{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook constitutes the session.\n",
    "\n",
    "Two choices: \n",
    "1. **Open** this notebook and follow along the presentation\n",
    "    * Open terminal\n",
    "    * Type `jupyter-notebook Introduction_Machine_Learning.ipynb`\n",
    "2. **Create** your own notebook and reproduce the different steps (warning!)\n",
    "    * Open terminal\n",
    "    * Type `jupyter-notebook My_ML_Notebook.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we start by **importing** the basic libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "> ML is a set of methods that can **automatically detect patterns** in data, and then use the uncovered patterns to **predict future data** (*from Machine Learning: A Probabilistic Perspective (Murphy 2012)*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phases\n",
    "\n",
    "1. **Training** an algorithm in machine learning means detecting patterns in a dataset\n",
    "1. **Testing** an algorithm means predicting future data, that is generalizing the uncovered trained patterns to new datasets\n",
    "\n",
    "### General workflow\n",
    "\n",
    "1. Load **datasets**:\n",
    "    * A **training dataset** \n",
    "        * it will be denoted as `X_train` \n",
    "        * in supervised setting, datasets also include a list of labels `y_train` associated to the samples in `X_train`\n",
    "        \n",
    "    * A **testing dataset** \n",
    "        * it will be denoted `X_test`\n",
    "        * in supervised setting, the list of labels is `y_test`\n",
    "\n",
    "1. Train the algorithm on the training dataset\n",
    "\n",
    "1. Test the trained algorithm on the testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning in python: scikit-learn\n",
    "\n",
    "We will demonstrate machine learning methods with scikit-learn (sklearn), one the most used machine learning library in python. If you don't have the library installed, you can refer to the [Instructions to workshop participants](https://github.com/florisvanvugt/workshop4june2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test if sklearn is installed:\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sklearn API**: http://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Toy Example: Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This dataset consists of 3 different types of irises’ (**Setosa**, **Versicolour**, and **Virginica**) given by their:\n",
    "* Sepal Length\n",
    "* Sepal Width\n",
    "* Petal Length \n",
    "* Petal Width.\n",
    "\n",
    "The classes are encoded as integers: \n",
    "* Setosa = 0\n",
    "* Versicolour = 1\n",
    "* Virginica = 2\n",
    "\n",
    "Rows are the samples and the columns the feature dimensions (Sepal Length, Sepal Width, Petal Length and Petal Width)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris dataset in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = iris.data\n",
    "labels = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of observations:', len(features), ' | Dimension:', len(features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Feature dimension is **4**, which makes it hard to visualize in a simple 2-d plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Choice 1:_ we select only the two first dimensions and visualize them in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x = features[:,0] # sepal length\n",
    "data_y = features[:,1] # sepal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(data_x, data_y, c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicit color for labels\n",
    "color_table = [[1.,0.,0.], [0.,1.,0.], [0.,0.,1.]]\n",
    "label_colors = [ color_table[l] for l in labels ]\n",
    "scatter(data_x, data_y, c=label_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x = features[:,2] # petal length\n",
    "data_y = features[:,3] # petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter(data_x, data_y, c=label_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Training a Classifier on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As use case, we will explore classifier training with the **Support Vector Machine (SVM)**\n",
    "\n",
    "The support vector machine, in its simplest version, is a **linear discriminant model**. \n",
    "\n",
    "Some usfule readings to know more about SVM:\n",
    "* C Cortes, V Vapnik. Support-vector networks. _Machine learning_ 20 (3), 273-297, 1995\n",
    "* B Schölkopf, AJ Smola. Learning with kernels: support vector machines, regularization, optimization, and beyond. *MIT press*, 2002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new SVM instance called `classifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the linear version (simpler) of support vector machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a supervised learning task, meaning that it learns the function mapping feature samples to known labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(features)):\n",
    "    print(features[n,:], '\\t==> ', labels[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(features, labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the two dimensions visualized previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(features[:,2:], labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES**\n",
    "* `fit` is the generic function to train any methods in sklearn\n",
    "* for supervised methods, `fit` accepts two arguments: the feature data and their labels, that is `fit(X_train, y_train)`\n",
    "* for unsupervised methods, `fit` accepts only one argument: the feature data, that is `fit(X_train)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding training in SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding training procedure in machine learning starts by understanding the **decision boundary** which is the set of borders delimiting regions in the feature space associated to each labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the two last dimensions of the iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter(features[:,2], features[:,3], c=label_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider only two classes given by the <span style=\"color:#DD0000;\">**RED**</span> and <span style=\"color:#00DD00;\">**GREEN**</span> colours (class 0 and 1 respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where( (labels == 0) | (labels == 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_indexes = np.where( (labels == 0) | (labels == 1) )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = features[class_indexes, 2:]\n",
    "y_train = labels[class_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_colors_2classes = np.array(label_colors)[class_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=label_colors_2classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: what is the best decision boundary between classes 0 and 1?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models, such as SVM, consider linear decision boundaries, which means here a **line**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line can be define by 2 parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope = -0.1\n",
    "intercept = 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the corresponding line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(1,5)\n",
    "boundary_y = slope * boundary_x + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=label_colors_2classes)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is that good enough?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=label_colors_2classes)\n",
    "plot(boundary_x, boundary_y, '-k')\n",
    "scatter(3.5, 0.7, c='#444444', s=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with other parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope = -1.0\n",
    "intercept = 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(1,4)\n",
    "boundary_y = slope * boundary_x + intercept\n",
    "\n",
    "scatter(X_train[:,0], X_train[:,1], c=label_colors_2classes)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Looks better...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#AA1111; font-size: 16px;\">TRAINING</span>\n",
    "* means finding the best parameters wrt the set of samples\n",
    "* can often be understood as an OPTIMIZATION problem (i.e. finding a decision boundary such as miminzing a certain **cost function**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the result given by **SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier with the sub-dataset comprised of only 2 classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of training is given by the the `coef_` structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = classifier.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope = -coefs[0] / coefs[1]\n",
    "intercept = classifier.intercept_[0] / coefs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(1.5,3.5)\n",
    "boundary_y = slope * boundary_x - intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=label_colors_2classes)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with more than one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = features[:,2:]\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with more than one class, SVM finds decision boundaries between pair of classes:\n",
    "* Class 1 vs. Class 2\n",
    "* Class 1 vs. Class 3\n",
    "* Class 2 vs. Class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting decision boundary between Class 1 [white] and Class 3 [black]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 1\n",
    "\n",
    "coefs = classifier.coef_[case]\n",
    "\n",
    "slope = -coefs[0] / coefs[1]\n",
    "intercept = classifier.intercept_[case] / coefs[1]\n",
    "\n",
    "boundary_x = np.linspace(0,10)\n",
    "boundary_y = slope * boundary_x - intercept\n",
    "\n",
    "scatter(X_train[:,0], X_train[:,1], c=label_colors)\n",
    "plot(boundary_x, boundary_y, '-k')\n",
    "\n",
    "xlim([0.5,7.5])\n",
    "ylim([-0.5,3.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting decision boundary between Class 2 [grey] and Class 3 [black]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case = 2\n",
    "\n",
    "coefs = classifier.coef_[case]\n",
    "\n",
    "slope = -coefs[0] / coefs[1]\n",
    "intercept = classifier.intercept_[case] / coefs[1]\n",
    "\n",
    "boundary_x = np.linspace(0,10)\n",
    "boundary_y = slope * boundary_x - intercept\n",
    "\n",
    "scatter(X_train[:,0], X_train[:,1], c=label_colors)\n",
    "plot(boundary_x, boundary_y, '-k')\n",
    "\n",
    "xlim([0.5,7.5])\n",
    "ylim([-0.5,3.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the partitions the underlying vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(0.5, 7.5, 200)\n",
    "yy = np.linspace(-0.5, 3.0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zz = np.zeros((xx.shape[0],yy.shape[0]))\n",
    "for i in range(len(xx)):\n",
    "    for j in range(len(yy)):\n",
    "        zz[i,j] = classifier.predict( np.array([xx[i],yy[j]]).reshape(1,-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcolormesh(xx, yy, -zz.T, cmap=plt.cm.RdBu, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolors='k', cmap=plt.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Real-World Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the _musical genre_ dataset: https://github.com/florisvanvugt/workshop4june2017/tree/master/datasets/features.\n",
    "\n",
    "Description:\n",
    "* 5 classes that are the musical genres\n",
    "    * **Ambient**\n",
    "    * **Country**\n",
    "    * **Metal**\n",
    "    * **Rock n' Roll**\n",
    "    * **Symphonic**\n",
    "* There are 5 excerpts per class\n",
    "* Data features are the MFCC (Mel-Frequency Cepstral Coefficients) computed on each excerpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['ambient', 'country', 'metal', 'rocknroll', 'symphonic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excerpts = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "for c in classes:\n",
    "    for e in excerpts:\n",
    "        data = np.loadtxt('datasets/features/%s_%03i.mfcc'%(c,e), delimiter=',')\n",
    "        for d_vect in data:\n",
    "            features.append(list(d_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.array( features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning that we have **1625** samples and each sample had **48** dimensions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load labels associated to each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for c in classes:\n",
    "    for e in excerpts:\n",
    "        data = np.loadtxt('datasets/features/%s_%03i.mfcc'%(c,e), delimiter=',')\n",
    "        for d_vect in data:\n",
    "            labels.append( classes.index(c) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.array( labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[ [2, 100, 387, 1209, 1500] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each class is encoded as an integer such as:\n",
    "    * 'ambient' = 0\n",
    "    * 'country' = 1\n",
    "    * 'metal' = 2\n",
    "    * 'rocknroll' = 3\n",
    "    * 'symphonic' = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(features[:,1], features[:,2], c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# explicit color for labels?\n",
    "color_table = [[1.,0.,0.], [0.,1.,0.], [0.,0.,1.], [0.,1.,1.], [1.,1.,0.]]\n",
    "label_colors = [ color_table[l] for l in labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(len(color_table)):\n",
    "    scatter([0,0], [c,c], c=color_table[c], s=200)\n",
    "    ylabel('Class label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(features[:,1], features[:,2], c=label_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try with two other feature dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(features[:,10], features[:,27], c=label_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVM on this Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Train on the two dimensions visualized previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(features[:,1:3], labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, let's consider only two classes given by the <span style=\"color:#DD0000;\">**RED**</span> and <span style=\"color:#DDDD00;\">**YELLOW**</span> colours (class 0 and 4 respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where( (labels == 0) | (labels == 4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_indexes = np.where( (labels == 0) | (labels == 4) )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = features[class_indexes, 1:3]\n",
    "y_train = labels[class_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_colors_2classes = np.array(label_colors)[class_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=label_colors_2classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train classifier with the sub-dataset comprised of only 2 classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of training is given by the the `coef_` structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = classifier.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slope = -coefs[0] / coefs[1]\n",
    "intercept = classifier.intercept_[0] / coefs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_x = np.linspace(200,500)\n",
    "boundary_y = slope * boundary_x - intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(X_train[:,0], X_train[:,1], c=label_colors_2classes)\n",
    "plot(boundary_x, boundary_y, '-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend to multi-class training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = features[:,1:3]\n",
    "y_train = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(100, 500, 200)\n",
    "yy = np.linspace(-150, 150, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zz = np.zeros((xx.shape[0],yy.shape[0]))\n",
    "for i in range(len(xx)):\n",
    "    for j in range(len(yy)):\n",
    "        zz[i,j] = classifier.predict( np.array([xx[i],yy[j]]).reshape(1,-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcolormesh(xx, yy, -zz.T, cmap=plt.cm.RdBu, alpha=0.1)\n",
    "scatter(X_train[:,0], X_train[:,1], c=y_train, edgecolors='k', cmap=plt.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Testing SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Reminder:_ ML method is trained on a **training dataset** and its generalizability is evaluated on a **testing dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here: **splitting** the dataset into training and testing sub-datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting datasets in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the API: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection\n",
    "\n",
    "Function | Description\n",
    "--- | ---\n",
    "`model_selection.KFold([n_splits, shuffle, ...])` | K-Folds cross-validator\n",
    "`model_selection.GroupKFold([n_splits])`\t| K-fold iterator variant with non-overlapping groups.\n",
    "`model_selection.StratifiedKFold([n_splits, ...])`\t| Stratified K-Folds cross-validator\n",
    "`model_selection.LeaveOneGroupOut()`\t| Leave One Group Out cross-validator\n",
    "`model_selection.LeavePGroupsOut(n_groups)`\t| Leave P Group(s) Out cross-validator\n",
    "`model_selection.LeaveOneOut()`\t| Leave-One-Out cross-validator\n",
    "`model_selection.LeavePOut(p)`\t| Leave-P-Out cross-validator\n",
    "`model_selection.ShuffleSplit([n_splits, ...])`\t| Random permutation cross-validator\n",
    "`model_selection.GroupShuffleSplit([...])`\t| Shuffle-Group(s)-Out cross-validation iterator\n",
    "`model_selection.StratifiedShuffleSplit([...])`\t| Stratified ShuffleSplit cross-validator\n",
    "`model_selection.PredefinedSplit(test_fold)`\t| Predefined split cross-validator\n",
    "`model_selection.TimeSeriesSplit([n_splits])`\t| Time Series cross-validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with **stratified k-fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold( n_splits=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the two dimensions plotted previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array( features[:,1:3] )\n",
    "y = np.array( labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in splitter.split(X,y):\n",
    "    print(\"training:\", labels[train_index])\n",
    "    print(\"testing:\", labels[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SVM on the splitted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index, test_index = next(splitter.split(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X_train = X[train_index]\n",
    "y_train = y[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing dataset\n",
    "X_test = X[test_index]\n",
    "y_test = y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init SVM classifier\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "\n",
    "# train VM classifier\n",
    "classifier.fit(X_train, y_train)   \n",
    "    \n",
    "# test SVM classifier and store output\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of errors of our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_errors = 0\n",
    "for i,yi in enumerate(y_pred):\n",
    "    if (yi != y_test[i]):\n",
    "        num_errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0 - num_errors/len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually compute the score directly into sklearn with `score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn function\n",
    "score = classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUT** we test only on one split, what if the split leads to particularly well disciminated training dataset but not testing dataset. Or the contrary... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to consider more than one split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test  = X[test_index]\n",
    "    y_test  = y[test_index]   \n",
    "    \n",
    "    # declare classifier\n",
    "    classifier = svm.SVC(kernel='linear')\n",
    "    classifier.fit(X_train,y_train)   \n",
    "    \n",
    "    # compute score on testing dataset and store it\n",
    "    score = classifier.score(X_test,y_test)\n",
    "    all_scores.append(score)  \n",
    "    \n",
    "    # print score\n",
    "    print('score: %.2f%%'%(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(all_scores)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(all_scores)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of evaluating a model on various splits within a bigger dataset is called **CROSS-VALIDATION**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Comparing Different Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we usually compare various models in order to pick the best one for a particular application. Model comparison can be done through cross-validation.\n",
    "\n",
    "For the sake of comparison, we compare classification accuracy for three classifiers:\n",
    "* Linear SVM\n",
    "    *  `svm.SVC(kernel='linear')`\n",
    "* Non-linear SVM\n",
    "    * `svm.SVC(kernel='rbf')`\n",
    "* k-Nearest Neighbour\n",
    "    * `neighbors.KNeighborsClassifier()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load kNN classifier from the sklearn library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we write a for loop on the dataset splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['SVM-linear', 'SVM-nonlinear', 'kNN']\n",
    "all_scores = {'SVM-linear': [], 'SVM-nonlinear': [], 'kNN': []}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]   \n",
    "    \n",
    "    \n",
    "    for clf in classifiers:\n",
    "        \n",
    "        # declare classifier\n",
    "        if (clf=='SVM-linear'):\n",
    "            classifier = svm.SVC(kernel='linear')\n",
    "        elif (clf=='SVM-nonlinear'):\n",
    "            classifier = svm.SVC(kernel='rbf')\n",
    "        elif (clf=='kNN'):\n",
    "            classifier = neighbors.KNeighborsClassifier()\n",
    "            \n",
    "        # train classifier\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        # compute score on testing dataset and store it\n",
    "        score = classifier.score(X_test,y_test)\n",
    "        all_scores[clf].append(score)  \n",
    "    \n",
    "        # print score\n",
    "        print(clf, 'score: %.2f%%'%(score*100)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    print(clf, 'mean score: %.2f%%'%(np.mean(all_scores[clf])*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitions(classifier_, X_train_, y_train_):\n",
    "    xx = np.linspace( np.min(X_train_[:,0]), np.max(X_train_[:,0]), 200 )\n",
    "    yy = np.linspace( np.min(X_train_[:,1]), np.max(X_train_[:,1]), 200 )\n",
    "    zz = np.zeros( (xx.shape[0],yy.shape[0]) )\n",
    "    for i in range(len(xx)):\n",
    "        for j in range(len(yy)):\n",
    "            zz[i,j] = classifier_.predict( np.array([xx[i],yy[j]]).reshape(1,-1) )\n",
    "    scatter(X_train_[:,0], X_train_[:,1], c=y_train_, edgecolors='k', cmap=plt.cm.RdBu_r)\n",
    "    pcolormesh(xx, yy, -zz.T, cmap=plt.cm.RdBu, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figure(figsize=(16,5))\n",
    "\n",
    "for i,clf in enumerate(['SVM-linear', 'kNN']):\n",
    "    \n",
    "    subplot(1,2,i+1)\n",
    "\n",
    "    if (clf=='SVM-linear'):\n",
    "        classifier = svm.SVC(kernel='linear')\n",
    "\n",
    "    elif (clf=='kNN'):\n",
    "        classifier = neighbors.KNeighborsClassifier()\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    partitions(classifier, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametric vs. Non-Parametric methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing classifiers on the original vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array( features )\n",
    "y = np.array( labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['SVM-linear', 'SVM-nonlinear', 'kNN']\n",
    "all_scores = {'SVM-linear': [], 'SVM-nonlinear': [], 'kNN': []}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]   \n",
    "    \n",
    "    \n",
    "    for clf in classifiers:\n",
    "        \n",
    "        # declare classifier\n",
    "        if (clf=='SVM-linear'):\n",
    "            classifier = svm.SVC(kernel='linear')\n",
    "        elif (clf=='SVM-nonlinear'):\n",
    "            classifier = svm.SVC(kernel='rbf')\n",
    "        elif (clf=='kNN'):\n",
    "            classifier = neighbors.KNeighborsClassifier()\n",
    "            \n",
    "        # train classifier\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        # compute score on testing dataset and store it\n",
    "        score = classifier.score(X_test,y_test)\n",
    "        all_scores[clf].append(score)  \n",
    "    \n",
    "        # print score\n",
    "        print(clf, 'score: %.2f%%'%(score*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    print('-', clf, 'mean score: %.2f%%'%(np.mean(all_scores[clf])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-linear SVM returns classification accuracy at **chance level** (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Some techniques are sensitive to the input vectors range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['SVM-linear', 'SVM-nonlinear', 'kNN']\n",
    "all_scores = {'SVM-linear': [], 'SVM-nonlinear': [], 'kNN': []}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in splitter.split(X,y):\n",
    "\n",
    "    # select training and testing datasets\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]   \n",
    "    \n",
    "    \n",
    "    for clf in classifiers:\n",
    "        \n",
    "        # declare classifier\n",
    "        if (clf=='SVM-linear'):\n",
    "            classifier = svm.SVC(kernel='linear')\n",
    "        elif (clf=='SVM-nonlinear'):\n",
    "            classifier = svm.SVC(kernel='rbf')\n",
    "        elif (clf=='kNN'):\n",
    "            classifier = neighbors.KNeighborsClassifier()\n",
    "            \n",
    "        # train classifier\n",
    "        X_train = np.subtract( X_train, np.mean(X_train, axis=0) )\n",
    "        X_train = np.divide( X_train, np.std(X_train, axis=0) )\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        # compute score on testing dataset and store it\n",
    "        X_test = np.subtract( X_test, np.mean(X_test, axis=0) )\n",
    "        X_test = np.divide( X_test, np.std(X_test, axis=0) )\n",
    "        score = classifier.score(X_test,y_test)\n",
    "        all_scores[clf].append(score)  \n",
    "    \n",
    "for clf in classifiers:\n",
    "    print('-', clf, 'mean score: %.2f%%'%(np.mean(all_scores[clf])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "* Sklearn has several functions to pre-process data before feeding them to some classifiers or regressors\n",
    "* More: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "About this material: copyright Baptiste Caramiaux (write me for any questions or use of this material [email](mailto:baptiste.caramiaux@ircam.fr))\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
